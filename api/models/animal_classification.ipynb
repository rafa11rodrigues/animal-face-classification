{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Animal face classification\n","\n"," This is a simple prototype to predict animal faces."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from zipfile import ZipFile\n","import pickle\n","import numpy as np\n","from deepfeatx.image import ImageFeatureExtractor as imgExt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","import gradio as gd\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Unzipping file\r\n"," It assumes that the file __data.zip__ is present in the same folder.\r\n","\r\n"," This file comes from [this](https://www.kaggle.com/andrewmvd/animal-faces) database."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["with ZipFile('data.zip', 'r') as zipped:\n","    zipped.extractall()\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Loading training data\n"," Images are loaded from disk and converted to feature vector using a pre-trained convolutional neural network.\n","\n"," Along the feature vector, image label is also returned, as well as the image path."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 14630 images belonging to 3 classes.\n","458/458 [==============================] - 710s 2s/step\n"]}],"source":["training = imgExt().extract_features_from_directory('data/train', export_class_names=True)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filepaths</th>\n","      <th>classes</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>...</th>\n","      <th>2038</th>\n","      <th>2039</th>\n","      <th>2040</th>\n","      <th>2041</th>\n","      <th>2042</th>\n","      <th>2043</th>\n","      <th>2044</th>\n","      <th>2045</th>\n","      <th>2046</th>\n","      <th>2047</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>data/training\\cat\\flickr_cat_000002.jpg</td>\n","      <td>cat</td>\n","      <td>0.017109</td>\n","      <td>0.152434</td>\n","      <td>0.000000</td>\n","      <td>0.193805</td>\n","      <td>0.524241</td>\n","      <td>0.071501</td>\n","      <td>0.123126</td>\n","      <td>0.107830</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.053416</td>\n","      <td>0.304579</td>\n","      <td>0.661124</td>\n","      <td>0.000000</td>\n","      <td>0.070440</td>\n","      <td>1.919095</td>\n","      <td>0.047214</td>\n","      <td>0.091598</td>\n","      <td>0.109597</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>data/training\\cat\\flickr_cat_000003.jpg</td>\n","      <td>cat</td>\n","      <td>0.359051</td>\n","      <td>0.669020</td>\n","      <td>0.002149</td>\n","      <td>0.285272</td>\n","      <td>0.651593</td>\n","      <td>0.684492</td>\n","      <td>0.818901</td>\n","      <td>0.060350</td>\n","      <td>...</td>\n","      <td>0.400328</td>\n","      <td>0.096731</td>\n","      <td>0.000000</td>\n","      <td>0.837292</td>\n","      <td>0.041907</td>\n","      <td>0.005843</td>\n","      <td>1.734416</td>\n","      <td>0.496650</td>\n","      <td>0.133781</td>\n","      <td>0.096114</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>data/training\\cat\\flickr_cat_000004.jpg</td>\n","      <td>cat</td>\n","      <td>0.294523</td>\n","      <td>0.854209</td>\n","      <td>0.297969</td>\n","      <td>0.272979</td>\n","      <td>0.575808</td>\n","      <td>0.554063</td>\n","      <td>0.473147</td>\n","      <td>0.051065</td>\n","      <td>...</td>\n","      <td>0.067802</td>\n","      <td>0.000000</td>\n","      <td>0.342157</td>\n","      <td>0.623310</td>\n","      <td>0.197095</td>\n","      <td>0.000000</td>\n","      <td>1.469772</td>\n","      <td>0.404472</td>\n","      <td>0.165518</td>\n","      <td>0.409393</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>data/training\\cat\\flickr_cat_000005.jpg</td>\n","      <td>cat</td>\n","      <td>0.265239</td>\n","      <td>0.638123</td>\n","      <td>0.046134</td>\n","      <td>0.166363</td>\n","      <td>0.240085</td>\n","      <td>0.141123</td>\n","      <td>0.504790</td>\n","      <td>0.037237</td>\n","      <td>...</td>\n","      <td>0.091863</td>\n","      <td>0.000000</td>\n","      <td>0.145260</td>\n","      <td>0.087608</td>\n","      <td>0.077971</td>\n","      <td>0.000000</td>\n","      <td>1.520948</td>\n","      <td>0.168698</td>\n","      <td>0.340189</td>\n","      <td>0.257377</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>data/training\\cat\\flickr_cat_000006.jpg</td>\n","      <td>cat</td>\n","      <td>0.534863</td>\n","      <td>0.686893</td>\n","      <td>0.118877</td>\n","      <td>0.201426</td>\n","      <td>0.814117</td>\n","      <td>0.295828</td>\n","      <td>0.731437</td>\n","      <td>0.447083</td>\n","      <td>...</td>\n","      <td>0.205050</td>\n","      <td>0.237526</td>\n","      <td>0.041880</td>\n","      <td>1.111808</td>\n","      <td>0.018326</td>\n","      <td>0.000000</td>\n","      <td>1.371500</td>\n","      <td>0.125551</td>\n","      <td>0.249915</td>\n","      <td>0.057478</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 2050 columns</p>\n","</div>"],"text/plain":["                                 filepaths classes         0         1  \\\n","0  data/training\\cat\\flickr_cat_000002.jpg     cat  0.017109  0.152434   \n","1  data/training\\cat\\flickr_cat_000003.jpg     cat  0.359051  0.669020   \n","2  data/training\\cat\\flickr_cat_000004.jpg     cat  0.294523  0.854209   \n","3  data/training\\cat\\flickr_cat_000005.jpg     cat  0.265239  0.638123   \n","4  data/training\\cat\\flickr_cat_000006.jpg     cat  0.534863  0.686893   \n","\n","          2         3         4         5         6         7  ...      2038  \\\n","0  0.000000  0.193805  0.524241  0.071501  0.123126  0.107830  ...  0.000000   \n","1  0.002149  0.285272  0.651593  0.684492  0.818901  0.060350  ...  0.400328   \n","2  0.297969  0.272979  0.575808  0.554063  0.473147  0.051065  ...  0.067802   \n","3  0.046134  0.166363  0.240085  0.141123  0.504790  0.037237  ...  0.091863   \n","4  0.118877  0.201426  0.814117  0.295828  0.731437  0.447083  ...  0.205050   \n","\n","       2039      2040      2041      2042      2043      2044      2045  \\\n","0  0.053416  0.304579  0.661124  0.000000  0.070440  1.919095  0.047214   \n","1  0.096731  0.000000  0.837292  0.041907  0.005843  1.734416  0.496650   \n","2  0.000000  0.342157  0.623310  0.197095  0.000000  1.469772  0.404472   \n","3  0.000000  0.145260  0.087608  0.077971  0.000000  1.520948  0.168698   \n","4  0.237526  0.041880  1.111808  0.018326  0.000000  1.371500  0.125551   \n","\n","       2046      2047  \n","0  0.091598  0.109597  \n","1  0.133781  0.096114  \n","2  0.165518  0.409393  \n","3  0.340189  0.257377  \n","4  0.249915  0.057478  \n","\n","[5 rows x 2050 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["training.head()\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Preprocessing\n"," Here the training set is divided in training and validation. Furthermore, X and Y arrays are separated.\n","\n"," Train and validation sets have the same sample proportion for each label."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["x = training.drop(columns=['filepaths', 'classes'])\n","y = training['classes']\n","x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train shape: (11704, 2048); y_train shape: (11704,)\n","x_val shape: (2926, 2048); y_val shape: (2926,)\n"]}],"source":["print(f'x_train shape: {x_train.shape}; y_train shape: {y_train.shape}')\n","print(f'x_val shape: {x_val.shape}; y_val shape: {y_val.shape}')\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["cat     0.352187\n","wild    0.323906\n","dog     0.323906\n","Name: classes, dtype: float64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["y_train.value_counts(normalize=True)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["cat     0.352358\n","dog     0.323992\n","wild    0.323650\n","Name: classes, dtype: float64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["y_val.value_counts(normalize=True)\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Training a model\n"," A logistic regression model is trained to make the predictions later."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train accuracy: 1.0\n","validation accuracy: 0.9982911825017088\n"]}],"source":["logisticRegression = LogisticRegression(n_jobs=-1)\n","logisticRegression.fit(x_train, y_train)\n","print(f'train accuracy: {logisticRegression.score(x_train, y_train)}')\n","print(f'validation accuracy: {logisticRegression.score(x_val, y_val)}')\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Testing the model\r\n","Here, new data is loaded to test the model."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1500 images belonging to 3 classes.\n","24/24 [==============================] - 75s 3s/step\n"]}],"source":["testing = imgExt().extract_features_from_directory('data/val', export_class_names=True, batch_size=64)\r\n","x_test = testing.drop(columns=['filepaths', 'classes'])\r\n","y_test = testing['classes']\r\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test accuracy: 0.9986666666666667\n"]}],"source":["print(f'test accuracy: {logisticRegression.score(x_test, y_test)}')\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Storing the model\n"," At the end, the model is stored to be used in whatever application."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["with open('model.pkl', 'wb') as model:\n","    pickle.dump(logisticRegression, model)\n"]},{"cell_type":"markdown","metadata":{},"source":[" ## Live demo\n"," Here there's a simple interface to submit new images and see the results."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Running locally at: http://127.0.0.1:7860/\n","To create a public link, set `share=True` in `launch()`.\n","Interface loading below...\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"900\"\n","            height=\"500\"\n","            src=\"http://127.0.0.1:7860/\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x222e41efd30>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(<Flask 'gradio.networking'>, 'http://127.0.0.1:7860/', None)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["with open('model.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","\n","def classify(img):\n","    features = imgExt().img_to_vector(img)\n","    probs = model.predict_proba(features)[0]\n","    idx = np.argmax(probs)\n","    pred = model.classes_[idx]\n","    prob = probs[idx] * 100.0\n","    return f'class: {pred}; confidence: {prob:.2f}'\n","\n","gd_input = gd.inputs.Image(type='pil')\n","gd.Interface(fn=classify, inputs=gd_input, outputs='text').launch()\n"]}],"metadata":{"interpreter":{"hash":"96e4cd4559f420b337cff5e6e94c280d73a970df8418c12f136cdcb524bea702"},"kernelspec":{"display_name":"Python 3.8.9 64-bit","name":"python3"},"language_info":{"name":"python","version":""},"orig_nbformat":2},"nbformat":4,"nbformat_minor":2}